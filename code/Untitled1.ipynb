{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF基线模型 + top选最长\n",
    "当前最佳得分模型\n",
    "\n",
    "tfidf模型，主要思路是：首先计算用户的问题与问题库中的问题的相似度并选出top15的相似问题，然后去问题库对应的答案库中找出这15个问题对应的答案， 以此作为回答用户问题的候选答案。代码参考：https://github.com/WenDesi/sentenceSimilarity 运行于python3.6环境下。\n",
    "\n",
    "用TFIDF方法做检索，其基本过程如下：\n",
    "假设输入查询为query，query中包含n个词语，分别是q1、q2、…、qn；语料库为D，包含若干个句子。\n",
    "\n",
    "step 1. 对语料库D中的所有句子进行分词；\n",
    "\n",
    "step 2. 构建bag-of-word模型，给每个词一个id；\n",
    "\n",
    "step 3. 计算语料库D中所有词的tfidf值；\n",
    "\n",
    "step 4. 计算语料库D中所有句子的tfidf向量表达；\n",
    "\n",
    "对于任一句子，其tfidf向量表达是句子中所有词的tfidf值构成的向量，保留词的先后顺序。\n",
    "step 5. 对query分词，生成tfidf向量表达，计算该向量与语料库D中所有句子向量的相似度，选取top N作为检索结果。\n",
    "\n",
    "基于TFIDF检索式方案，生成结果的方式默认是直接选择最相似的对话的A作为结果输出，这样做的问题是选择范围过于狭小。事实上，根据我们的观察，相似性top10的对话其实都比较接近，难以评判哪一个是最相似，因此，我们认为在top10相似对话的所有A中产生结果更为合理。\n",
    "\n",
    "随之而来的问题是，如何在10个候选结果中找出最好的结果，使得deltaBleu得分最高？最开始，我们采用强化学习中的DQN方法来进行选择，直接采用bleu得分作为奖励，但是并没有带来有效的提升，甚至得分下降。针对这种情况，我们分析的结论是：DQN的目标是优化长期奖励，不适用这种仅有一个回合的场景。使用强化学习的方案遇挫，我们不得不重新回到数据上寻找答案。**在逐个观察了约100个用户与客服的完整对话记录之后，我们发现，客服的回复通常倾向于比用户说的话更长，这个现象带来的启发是：在10个候选答案中选择最长的。**经测试，top10选最长的方案，大幅提升了deltaBleu评测得分，甚至一度冲上初赛排行榜第2名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666704\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "# import sklearn\n",
    "\n",
    "\n",
    "data_chat = pd.read_csv(\"../data/JDDC_100W训练数据集/训练数据集/chat_5per.txt\", sep = \"\\t\", engine=\"python\", \n",
    "                        warn_bad_lines = True, error_bad_lines = False, encoding = \"UTF-8\", header = None)\n",
    "\n",
    "n_row = data_chat.shape[0]\n",
    "print(n_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结巴分词，创建语料库\n",
    "\t这里做的工作很简单，就是将所有句子分句储存在texts中，text是一个list list对象\n",
    "\n",
    "## 根据语料库，创建词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1)]\n",
      "time cost 57.535338401794434 s\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import time\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "time_start=time.time()\n",
    "\n",
    "texts = []\n",
    "for i in range(n_row):\n",
    "    sentence = data_chat.iat[i, 6]\n",
    "    list_word = list(jieba.cut(sentence))\n",
    "    texts.append(list_word)\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus_simple = [dictionary.doc2bow(text) for text in texts]\n",
    "print(corpus_simple[0])\n",
    "\n",
    "time_end=time.time()\n",
    "print('time cost',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost 1.1690797805786133 s\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "\n",
    "tfidf = models.TfidfModel(corpus_simple)\n",
    "corpus_tfidf = tfidf[corpus_simple]\n",
    "# print(len(corpus[0]))\n",
    "# print(corpus[0])\n",
    "# print(len(corpus[1]))\n",
    "# print(corpus[1])\n",
    "# print(len(corpus[2]))\n",
    "# print(corpus[2])\n",
    "\n",
    "time_end=time.time()\n",
    "print('time cost',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算相似度矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost 103.05556917190552 s\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "\n",
    "# index = similarities.MatrixSimilarity(corpus)\n",
    "index = similarities.Similarity(\"../out/\", corpus_tfidf, len(dictionary))\n",
    "\n",
    "\n",
    "# with open(\"../data/JDDC_100W训练数据集/训练数据集/corpus_simple.pkl\", 'w') as f:\n",
    "#     pickle.dump([dictionary, corpus_simple], f)\n",
    "# tfidf.save(\"../data/JDDC_100W训练数据集/训练数据集/tfidf.model\")\n",
    "# index.save(\"../data/JDDC_100W训练数据集/训练数据集/index.index\")\n",
    "\n",
    "\n",
    "time_end=time.time()\n",
    "print('time cost',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 句子相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from .utils import Sentence\n",
    "\n",
    "## 先使用sentence2vec将需要匹配的句子传进去\n",
    "def sentence2vec(sentence):\n",
    "    list_word = list(jieba.cut(sentence))\n",
    "    vec_bow = dictionary.doc2bow(list_word)\n",
    "    return tfidf[vec_bow]\n",
    "\n",
    "def similarity(sentence, top=30):\n",
    "    \"\"\"求最相似的句子\"\"\"\n",
    "    sentence_vec = sentence2vec(sentence)\n",
    "    sims = index[sentence_vec]\n",
    "\n",
    "    # 按相似度降序排序\n",
    "    sim_sort = sorted(list(enumerate(sims)), key=lambda item: item[1], reverse=True)\n",
    "    top_k = sim_sort[0:top]\n",
    "\n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(218187, 0.59509856), (542883, 0.5943369), (17651, 0.5550804), (39164, 0.52501005), (59835, 0.52501005), (264743, 0.52501005), (309591, 0.52501005), (339316, 0.52501005), (356899, 0.52501005), (372449, 0.52501005), (481513, 0.52501005), (533146, 0.52501005), (555419, 0.52501005), (558125, 0.52501005), (588413, 0.52501005), (592525, 0.52501005), (593547, 0.52501005), (650065, 0.52501005), (29916, 0.5058065), (52324, 0.5058065), (70371, 0.5058065), (141774, 0.5058065), (198400, 0.5058065), (355376, 0.5058065), (370028, 0.5058065), (374732, 0.5058065), (414082, 0.5058065), (462072, 0.5058065), (481839, 0.5058065), (507319, 0.5058065)]\n",
      "但是优惠券如果不在有效期内的话，会直接作废的\n",
      "什么原因\n",
      "γ元京券\n",
      "ααα\n",
      "差价呢\n",
      "您没有申请售后呢\n",
      "是正常安排送货的 非常抱歉α\n",
      "您已经取消了哦\n",
      "现在商品京 东 价 ￥ζ\n",
      "那这边把您尝试反馈一下呢\n",
      "γ 小米 红米NoteγA 全网通版 γGB+γ2GB 铂银灰 移动联通电信γG手机 双卡双待\n",
      "你看不到单号???\n",
      "您是什么时候换手机号码的\n",
      "现在就是等配送回应的状态了\n",
      "好奇你长什么样子\n",
      "我之前解释的不对，抱歉\n",
      "现在商品的金额是γ，您购买的时候是γ哦\n",
      "服务器的问题\n",
      "请问您是咨询之前的问题还是有其他的问题需要处理呢?\n",
      "可以给您办理退货的呢亲爱的\n",
      "亲爱的客户 这个 不是上门提货吗 您去 实体店看下 能不能\n",
      "您已经申请取消订单了呢\n",
      "麻烦您耐心等待一下，给您带来不便，还请您见谅~ 是的哦 应该很快的哦 正常下午就可以查看的呢\n",
      "这个无法确定呢 是呢\n",
      "微信号:“京东饭粒”公众号(jd_fanli)，通过公众号也可以下单\n",
      "我们这边的最新信息是这条哦\n",
      "亲亲，这个订单号吗?\n",
      "您的这个是已经出库了呢\n",
      "明天上午为您送达哦\n",
      "我再次为您核实\n"
     ]
    }
   ],
   "source": [
    "result = similarity(\"店铺劵都有啥\")\n",
    "print(result)\n",
    "for answer in result:\n",
    "    print(data_chat.iat[answer[0]+1, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 余弦相似度函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8164965809277259\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "def get_word_vector(s1,s2):\n",
    "    \"\"\"\n",
    "    :param s1: 句子1\n",
    "    :param s2: 句子2\n",
    "    :return: 返回句子的余弦相似度\n",
    "    \"\"\"\n",
    "    # 分词\n",
    "    cut1 = jieba.cut(s1)\n",
    "    cut2 = jieba.cut(s2)\n",
    "    list_word1 = (','.join(cut1)).split(',')\n",
    "    list_word2 = (','.join(cut2)).split(',')\n",
    "\n",
    "    # 列出所有的词,取并集\n",
    "    key_word = list(set(list_word1 + list_word2))\n",
    "    # 给定形状和类型的用0填充的矩阵存储向量\n",
    "    word_vector1 = np.zeros(len(key_word))\n",
    "    word_vector2 = np.zeros(len(key_word))\n",
    "\n",
    "    # 计算词频\n",
    "    # 依次确定向量的每个位置的值\n",
    "    for i in range(len(key_word)):\n",
    "        # 遍历key_word中每个词在句子中的出现次数\n",
    "        for j in range(len(list_word1)):\n",
    "            if key_word[i] == list_word1[j]:\n",
    "                word_vector1[i] += 1\n",
    "        for k in range(len(list_word2)):\n",
    "            if key_word[i] == list_word2[k]:\n",
    "                word_vector2[i] += 1\n",
    "\n",
    "    # 输出向量\n",
    "#     print(word_vector1)\n",
    "#     print(word_vector2)\n",
    "    return word_vector1, word_vector2\n",
    "\n",
    "def cos_dist(s1, s2):\n",
    "    \"\"\"\n",
    "    :param vec1: 向量1\n",
    "    :param vec2: 向量2\n",
    "    :return: 返回两个向量的余弦相似度\n",
    "    \"\"\"\n",
    "    vec1, vec2 = get_word_vector(s1, s2)\n",
    "    dist1= float(np.dot(vec1,vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2)))\n",
    "    return dist1\n",
    "\n",
    "print(cos_dist(\"我喜欢\", \"我也喜欢\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "但是优惠券如果不在有效期内的话，会直接作废的\n",
      "0.0\n",
      "[[0.         0.         0.         0.         0.12403473 0.\n",
      "  0.1672484  0.         0.0438529  0.         0.         0.\n",
      "  0.1869894  0.         0.         0.09245003 0.         0.2802851\n",
      "  0.         0.         0.05547002 0.         0.09805807 0.1132277\n",
      "  0.09805807 0.         0.         0.         0.13867505 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.36661779 0.         0.         0.         0.        ]\n",
      " [0.12403473 0.         0.         0.         0.         0.\n",
      "  0.40451992 0.15811388 0.10606602 0.         0.16903085 0.\n",
      "  0.33166248 0.07071068 0.2        0.2236068  0.1        0.22597307\n",
      "  0.2236068  0.         0.         0.15811388 0.23717082 0.09128709\n",
      "  0.39528471 0.         0.09128709 0.1        0.2236068  0.1860521 ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.33333333 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.1672484  0.         0.         0.         0.40451992 0.\n",
      "  0.         0.21320072 0.19069252 0.         0.22792115 0.\n",
      "  0.48786938 0.09534626 0.26967994 0.20100756 0.13483997 0.22852652\n",
      "  0.20100756 0.         0.06030227 0.21320072 0.21320072 0.\n",
      "  0.42640143 0.         0.12309149 0.13483997 0.30151134 0.        ]\n",
      " [0.         0.         0.         0.         0.15811388 0.\n",
      "  0.21320072 0.         0.         0.         0.26726124 0.\n",
      "  0.09534626 0.2236068  0.31622777 0.         0.         0.11909827\n",
      "  0.47140452 0.         0.         0.25       0.         0.\n",
      "  0.25       0.         0.         0.         0.         0.        ]\n",
      " [0.0438529  0.         0.         0.         0.10606602 0.\n",
      "  0.19069252 0.         0.         0.47434165 0.05976143 0.\n",
      "  0.4477215  0.         0.07071068 0.31622777 0.07071068 0.07989355\n",
      "  0.31622777 0.59292706 0.         0.0559017  0.0559017  0.12909944\n",
      "  0.1677051  0.57384761 0.06454972 0.07071068 0.07905694 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.47434165 0.         0.18898224 0.\n",
      "  0.20225996 0.         0.         0.16666667 0.2236068  0.\n",
      "  0.16666667 0.375      0.         0.         0.         0.20412415\n",
      "  0.1767767  0.36293309 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.16903085 0.\n",
      "  0.22792115 0.26726124 0.05976143 0.18898224 0.         0.\n",
      "  0.20385888 0.11952286 0.50709255 0.         0.6761234  0.1273214\n",
      "  0.25197632 0.         0.         0.26726124 0.         0.\n",
      "  0.53452248 0.         0.15430335 0.16903085 0.18898224 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.29774567\n",
      "  0.         0.1767767  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.1869894  0.         0.         0.         0.33166248 0.\n",
      "  0.48786938 0.09534626 0.4477215  0.20225996 0.20385888 0.\n",
      "  0.         0.08528029 0.24120908 0.35957326 0.30151134 0.34066723\n",
      "  0.26967994 0.30338994 0.08090398 0.23836565 0.28603878 0.11009638\n",
      "  0.38138504 0.29362733 0.27524094 0.18090681 0.20225996 0.        ]\n",
      " [0.         0.         0.         0.         0.07071068 0.\n",
      "  0.09534626 0.2236068  0.         0.         0.11952286 0.\n",
      "  0.08528029 0.         0.28284271 0.         0.         0.05326236\n",
      "  0.21081851 0.         0.         0.2236068  0.1118034  0.\n",
      "  0.1118034  0.         0.         0.14142136 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.2        0.\n",
      "  0.26967994 0.31622777 0.07071068 0.         0.50709255 0.\n",
      "  0.24120908 0.28284271 0.         0.         0.2        0.15064872\n",
      "  0.2981424  0.         0.         0.31622777 0.         0.\n",
      "  0.31622777 0.         0.18257419 0.2        0.         0.        ]\n",
      " [0.09245003 0.         0.         0.         0.2236068  0.33333333\n",
      "  0.20100756 0.         0.31622777 0.16666667 0.         0.\n",
      "  0.35957326 0.         0.         0.         0.         0.05614346\n",
      "  0.22222222 0.25       0.         0.         0.23570226 0.\n",
      "  0.23570226 0.2419554  0.         0.         0.16666667 0.        ]\n",
      " [0.         0.         0.         0.         0.1        0.\n",
      "  0.13483997 0.         0.07071068 0.2236068  0.6761234  0.\n",
      "  0.30151134 0.         0.2        0.         0.         0.07532436\n",
      "  0.         0.         0.         0.15811388 0.15811388 0.\n",
      "  0.47434165 0.         0.36514837 0.2        0.         0.        ]\n",
      " [0.2802851  0.         0.         0.         0.22597307 0.\n",
      "  0.22852652 0.11909827 0.07989355 0.         0.1273214  0.29774567\n",
      "  0.34066723 0.05326236 0.15064872 0.05614346 0.07532436 0.\n",
      "  0.11228692 0.10526899 0.15158735 0.14887283 0.05954913 0.24066496\n",
      "  0.1786474  0.         0.06876142 0.07532436 0.08421519 0.        ]\n",
      " [0.         0.         0.         0.         0.2236068  0.\n",
      "  0.20100756 0.47140452 0.31622777 0.16666667 0.25197632 0.\n",
      "  0.26967994 0.21081851 0.2981424  0.22222222 0.         0.11228692\n",
      "  0.         0.25       0.         0.23570226 0.11785113 0.13608276\n",
      "  0.47140452 0.2419554  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.59292706 0.375      0.         0.1767767\n",
      "  0.30338994 0.         0.         0.25       0.         0.10526899\n",
      "  0.25       0.         0.         0.         0.         0.\n",
      "  0.         0.54439964 0.         0.         0.         0.        ]\n",
      " [0.05547002 0.         0.         0.         0.         0.\n",
      "  0.06030227 0.         0.         0.         0.         0.\n",
      "  0.08090398 0.         0.         0.         0.         0.15158735\n",
      "  0.         0.         0.         0.         0.         0.08164966\n",
      "  0.         0.         0.         0.         0.         0.11094004]\n",
      " [0.         0.         0.         0.         0.15811388 0.\n",
      "  0.21320072 0.25       0.0559017  0.         0.26726124 0.\n",
      "  0.23836565 0.2236068  0.31622777 0.         0.15811388 0.14887283\n",
      "  0.23570226 0.         0.         0.         0.125      0.\n",
      "  0.25       0.         0.14433757 0.15811388 0.         0.        ]\n",
      " [0.09805807 0.         0.         0.         0.23717082 0.\n",
      "  0.21320072 0.         0.0559017  0.         0.         0.\n",
      "  0.28603878 0.1118034  0.         0.23570226 0.15811388 0.05954913\n",
      "  0.11785113 0.         0.         0.125      0.         0.\n",
      "  0.25       0.         0.14433757 0.         0.1767767  0.        ]\n",
      " [0.1132277  0.         0.         0.         0.09128709 0.\n",
      "  0.         0.         0.12909944 0.20412415 0.         0.\n",
      "  0.11009638 0.         0.         0.         0.         0.24066496\n",
      "  0.13608276 0.         0.08164966 0.         0.         0.\n",
      "  0.14433757 0.         0.         0.         0.         0.33968311]\n",
      " [0.09805807 0.         0.         0.         0.39528471 0.\n",
      "  0.42640143 0.25       0.1677051  0.1767767  0.53452248 0.\n",
      "  0.38138504 0.1118034  0.31622777 0.23570226 0.47434165 0.1786474\n",
      "  0.47140452 0.         0.         0.25       0.25       0.14433757\n",
      "  0.         0.         0.14433757 0.15811388 0.1767767  0.        ]\n",
      " [0.         0.         0.         0.36661779 0.         0.\n",
      "  0.         0.         0.57384761 0.36293309 0.         0.\n",
      "  0.29362733 0.         0.         0.2419554  0.         0.\n",
      "  0.2419554  0.54439964 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.09128709 0.\n",
      "  0.12309149 0.         0.06454972 0.         0.15430335 0.\n",
      "  0.27524094 0.         0.18257419 0.         0.36514837 0.06876142\n",
      "  0.         0.         0.         0.14433757 0.14433757 0.\n",
      "  0.14433757 0.         0.         0.36514837 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.1        0.\n",
      "  0.13483997 0.         0.07071068 0.         0.16903085 0.\n",
      "  0.18090681 0.14142136 0.2        0.         0.2        0.07532436\n",
      "  0.         0.         0.         0.15811388 0.         0.\n",
      "  0.15811388 0.         0.36514837 0.         0.         0.        ]\n",
      " [0.13867505 0.         0.         0.         0.2236068  0.\n",
      "  0.30151134 0.         0.07905694 0.         0.18898224 0.\n",
      "  0.20225996 0.         0.         0.16666667 0.         0.08421519\n",
      "  0.         0.         0.         0.         0.1767767  0.\n",
      "  0.1767767  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.1860521  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11094004 0.         0.         0.33968311\n",
      "  0.         0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(data_chat.iat[result[0][0]+1, 6])\n",
    "print(cos_dist(data_chat.iat[result[0][0]+1, 6], data_chat.iat[result[1][0]+1, 6]))\n",
    "\n",
    "\n",
    "x_sim = np.zeros((len(result), len(result)))\n",
    "for i in range(len(result)):\n",
    "    for j in range(len(result)):\n",
    "        if i != j:\n",
    "            x_sim[i][j] = cos_dist(data_chat.iat[result[i][0]+1, 6], data_chat.iat[result[j][0]+1, 6]);\n",
    "#             print(\"i j: \" + str(i) + \" \" + str(j) + \" \" + str(cos_dist(data_chat.iat[result[i][0]+1, 6], data_chat.iat[result[j][0]+1, 6])))\n",
    "\n",
    "print(x_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAJQCAYAAACq1eFGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTJ8wl8JnMgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig,ax=plt.subplots(figsize=(10,20))\n",
    "im=ax.imshow(x_sim,cmap='plasma_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## result\n",
    "我们从top15中选取result的方式是选取和其他句子相似度和最大的。  \n",
    "从heatmap可以看出，13th句子和其他句子有最大相似度，其内容非常匹配Q。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 是正常安排送货的 非常抱歉α\n"
     ]
    }
   ],
   "source": [
    "x_sum = np.zeros((len(result,)))\n",
    "for i in range(len(result)):\n",
    "    x_sum[i] = x_sim[i].sum()\n",
    "n_result = np.argmax(x_sum)\n",
    "print(n_result, data_chat.iat[result[n_result][0]+1, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
